# Volaris Deployment Overview & Stabilization Analysis

## 1. System Architecture

### Current Deployment Configuration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RENDER PLATFORM                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Web Service (FREE TIER)      â”‚  â”‚  Background Worker       â”‚  â”‚
â”‚  â”‚   Memory: 512 MB               â”‚  â”‚  (STARTER - $7/mo)       â”‚  â”‚
â”‚  â”‚   âŒ Crashes at ~470-480 MB     â”‚  â”‚  Memory: 512 MB          â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚  âŒ Crashes at ~470-480 MBâ”‚  â”‚
â”‚  â”‚  Command:                      â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚
â”‚  â”‚  uvicorn app.main:app \        â”‚  â”‚  Command:                â”‚  â”‚
â”‚  â”‚    --host 0.0.0.0 \            â”‚  â”‚  python -m app.alerts    â”‚  â”‚
â”‚  â”‚    --port 10000                â”‚  â”‚    .discord_bot          â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  Components:                   â”‚  â”‚  Components:             â”‚  â”‚
â”‚  â”‚  â€¢ FastAPI application         â”‚  â”‚  â€¢ Discord bot (24/7)    â”‚  â”‚
â”‚  â”‚  â€¢ REST API endpoints          â”‚  â”‚  â€¢ APScheduler jobs      â”‚  â”‚
â”‚  â”‚  â€¢ DB connection pool (5+10)   â”‚  â”‚  â€¢ Alert polling (60s)   â”‚  â”‚
â”‚  â”‚  â€¢ Health checks               â”‚  â”‚  â€¢ Stream polling (60s)  â”‚  â”‚
â”‚  â”‚  â€¢ Router handlers             â”‚  â”‚  â€¢ Daily digest task     â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  Env Variables:                â”‚  â”‚  Env Variables:          â”‚  â”‚
â”‚  â”‚  â€¢ SCHEDULER_ENABLED=true âš ï¸   â”‚  â”‚  â€¢ SCHEDULER_ENABLED=trueâ”‚  â”‚
â”‚  â”‚  â€¢ DISCORD_BOT_ENABLED=true âš ï¸ â”‚  â”‚  â€¢ DISCORD_BOT_ENABLED=  â”‚  â”‚
â”‚  â”‚  â€¢ ENVIRONMENT=production      â”‚  â”‚      true                â”‚  â”‚
â”‚  â”‚  â€¢ LOG_LEVEL=info              â”‚  â”‚  â€¢ LOG_LEVEL=info        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                                      â”‚                   â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                          â”‚                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     EXTERNAL DEPENDENCIES (FREE TIER)    â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                                          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚  Neon PostgreSQL (FREE)            â”‚ â”‚
        â”‚  â”‚  â€¢ 0.5 GB storage per project      â”‚ â”‚
        â”‚  â”‚  â€¢ 190 compute hours/month         â”‚ â”‚
        â”‚  â”‚  â€¢ Max 2 CU (2 vCPU / 8 GB RAM)    â”‚ â”‚
        â”‚  â”‚  â€¢ Connection pool: 5 + 10 overflowâ”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚                                          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚  Upstash Redis (FREE)              â”‚ â”‚
        â”‚  â”‚  â€¢ 256 MB data                     â”‚ â”‚
        â”‚  â”‚  â€¢ 10K commands/day                â”‚ â”‚
        â”‚  â”‚  â€¢ Used for: token cache, rate     â”‚ â”‚
        â”‚  â”‚    limiting, session storage       â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚                                          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚  Market Data APIs (ALL CONFIGURED) â”‚ â”‚
        â”‚  â”‚  â€¢ Schwab (OAuth + refresh token)  â”‚ â”‚
        â”‚  â”‚  â€¢ Tiingo (EOD data)               â”‚ â”‚
        â”‚  â”‚  â€¢ Alpaca (historical)             â”‚ â”‚
        â”‚  â”‚  â€¢ Polygon (market data)           â”‚ â”‚
        â”‚  â”‚  â€¢ Finnhub (fundamentals)          â”‚ â”‚
        â”‚  â”‚  â€¢ Databento (backfills)           â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Runtime Behavior & Data Flow

### Background Worker Process Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKGROUND WORKER EXECUTION CYCLE                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  STARTUP (t=0s)                                                  â”‚
â”‚  â”œâ”€ Load Discord bot                                             â”‚
â”‚  â”œâ”€ Create APScheduler                                           â”‚
â”‚  â”œâ”€ Load 4 cog extensions (strategy, market_data, calculators,  â”‚
â”‚  â”‚  utilities)                                                   â”‚
â”‚  â”œâ”€ Sync slash commands to Discord guild                         â”‚
â”‚  â”œâ”€ Initialize DB connection pool (5 + 10 overflow)              â”‚
â”‚  â””â”€ Start 3 background tasks + 5 scheduler jobs                  â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  DISCORD BOT TASKS (discord.py event loop)                â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  1. poll_price_alerts (every 60s)                         â”‚  â”‚
â”‚  â”‚     â””â”€ HTTP â†’ Web API â†’ fetch triggered alerts           â”‚  â”‚
â”‚  â”‚  2. poll_price_streams (every 60s)                        â”‚  â”‚
â”‚  â”‚     â””â”€ HTTP â†’ Web API â†’ fetch active streams             â”‚  â”‚
â”‚  â”‚  3. daily_top_digest (cron: 9:30 AM ET)                   â”‚  â”‚
â”‚  â”‚     â””â”€ HTTP â†’ Web API â†’ fetch market movers              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  APSCHEDULER JOBS (AsyncIOScheduler)                      â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  1. realtime_prices_job (every 120s)                      â”‚  â”‚
â”‚  â”‚     â”œâ”€ Fetch ~500 S&P 500 tickers                         â”‚  â”‚
â”‚  â”‚     â”œâ”€ Batch size: 25 tickers per iteration               â”‚  â”‚
â”‚  â”‚     â”œâ”€ For each ticker: HTTP â†’ Schwab API                 â”‚  â”‚
â”‚  â”‚     â”œâ”€ Parse + upsert to Postgres (5-10 rows/ticker)      â”‚  â”‚
â”‚  â”‚     â””â”€ Memory spike: +50-100 MB                           â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  2. option_chain_refresh_job (every 30 min)               â”‚  â”‚
â”‚  â”‚     â”œâ”€ Fetch option chains for active tickers             â”‚  â”‚
â”‚  â”‚     â”œâ”€ HTTP â†’ Schwab API (large payloads)                 â”‚  â”‚
â”‚  â”‚     â”œâ”€ Parse contracts (100-200 per ticker)               â”‚  â”‚
â”‚  â”‚     â””â”€ Memory spike: +80-150 MB                           â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  3. iv_metric_job (every 60 min)                          â”‚  â”‚
â”‚  â”‚     â””â”€ Compute IV metrics from option chain snapshots     â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  4. refresh_sp500_job (weekly: Mon 6:00 AM)               â”‚  â”‚
â”‚  â”‚     â””â”€ Scrape S&P 500 constituents                        â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  âŒ REMOVED: prices_5m (redundant with prices_1m)          â”‚  â”‚
â”‚  â”‚  âŒ REMOVED: eod_sync (not needed for MVP)                 â”‚  â”‚
â”‚  â”‚  âŒ REMOVED: historical_backfill (one-time setup)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  MEMORY PATTERN (saw-tooth growth):                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  470 MB â”¤                          â•­â•®                    â•­â•® ðŸ’¥   â”‚
â”‚  400 MB â”¤                  â•­â•®     â•­â•¯â•°â•®          â•­â•®     â•­â•¯â•°â•®     â”‚
â”‚  350 MB â”¤          â•­â•®     â•­â•¯â•°â•®   â•­â•¯  â•°â•®        â•­â•¯â•°â•®   â•­â•¯  â•°â•®    â”‚
â”‚  300 MB â”¤  â•­â•®     â•­â•¯â•°â•®   â•­â•¯  â•°â•® â•­â•¯    â•°â•®â•­â•®   â•­â•¯  â•°â•® â•­â•¯    â•°â•®   â”‚
â”‚  250 MB â”¼â”€â”€â•¯â•°â”€â”€â”€â”€â”€â•¯â”€â”€â•°â”€â”€â”€â•¯â”€â”€â”€â”€â•°â”€â•¯â”€â”€â”€â”€â”€â”€â•°â•¯â•°â”€â”€â”€â•¯â”€â”€â”€â”€â•°â”€â•¯â”€â”€â”€â”€â”€â”€â•°â”€  â”‚
â”‚         0    5    10   15   20   25   30   35   40   45   50   â”‚
â”‚                          Time (minutes)                          â”‚
â”‚                                                                   â”‚
â”‚  ðŸ’¥ CRASH at 10-20 min: Memory reaches 470-480 MB                â”‚
â”‚     â””â”€ Render kills process (OOM)                                â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API Call Patterns

| **Component** | **Caller** | **Target** | **Frequency** | **Payload Size** | **Concurrency** |
|---|---|---|---|---|---|
| Discord commands | User interaction | Web API `/api/v1/*` | On-demand | 1-10 KB | 1-5 concurrent |
| Alert polling | Discord bot task | Web API `/api/v1/alerts/evaluate` | Every 60s | 5-50 KB | 1 connection |
| Stream polling | Discord bot task | Web API `/api/v1/streams/active` | Every 60s | 5-50 KB | 1 connection |
| Scheduler: prices_1m | APScheduler job | Schwab API `/marketdata/v1/pricehistory` | Every 120s | 2-10 KB/ticker Ã— 500 | 25 concurrent |
| Scheduler: options | APScheduler job | Schwab API `/marketdata/v1/chains` | Every 30 min | 50-200 KB/ticker | 1-5 concurrent |
| Scheduler: IV metrics | APScheduler job | Local DB queries | Every 60 min | N/A (compute) | N/A |

---

## 3. Critical Bottlenecks & Root Causes

### ðŸ”´ Primary Issue: Memory Leak in Background Worker

#### Root Causes Identified:

**1. Unclosed HTTP Sessions (90% of the problem)**
- **Location:** `app/alerts/helpers/api_client.py:72`
```python
async with aiohttp.ClientSession(timeout=self.timeout) as session:
    async with session.post(url, json=body) as response:
```
- **Problem:** Creates new `ClientSession` on **every Discord command** and **every polling cycle**
- **Impact:** Each session allocates ~1-2 MB; with 60s polling + user commands = **5-10 sessions/min**
- **Cumulative leak:** 5-10 MB/min = **50-100 MB in 10 minutes**

**2. BaseAPIClient (httpx) Persistence**
- **Location:** `app/services/base_client.py:43`
```python
self.client = httpx.AsyncClient(timeout=timeout)
```
- **Problem:** Client created in `__init__` but `close()` never called automatically
- **Impact:** Each provider client (Schwab, Tiingo, Alpaca, etc.) holds open connection pool
- **Usage:** 6 providers Ã— ~5-10 MB each = **30-60 MB persistent**

**3. Scheduler Job Overlap**
- **Location:** `app/workers/scheduler.py:46-54`
```python
scheduler.add_job(
    realtime_prices_job,
    trigger="interval",
    seconds=120,
    max_instances=1,  # âœ… Good: prevents overlap
    misfire_grace_time=30,  # âš ï¸ Problem: only 30s grace
)
```
- **Problem:** Job takes 60-90s to fetch 500 tickers (25 per batch)
- **Risk:** If job runs slow (API delays), next cycle starts before cleanup
- **Impact:** 2 concurrent jobs = **2Ã— memory usage** (100-200 MB spike)

**4. Discord Bot Persistent State**
- **Location:** `app/alerts/discord_bot.py:48`
```python
self.user_command_count: dict[int, list[float]] = {}  # Never pruned
```
- **Problem:** Rate limit tracking dictionary grows unbounded
- **Impact:** Minor (1-5 MB over weeks), but contributes to baseline

**5. S&P 500 Batch Processing**
- **Location:** `app/workers/tasks.py:116-127`
```python
for batch in batched(tickers, batch_size):  # batch_size=25
    for ticker in batch:
        response = await _fetch_price_payload(provider, ticker.symbol, ...)
```
- **Problem:** Fetches 500 tickers sequentially (25 at a time)
- **Duration:** 500 tickers Ã· 25 batch = 20 iterations Ã— 3-5s = **60-100 seconds**
- **Impact:** Long-lived job = more time for memory accumulation

---

### ðŸŸ¡ Secondary Issues

#### A. Discord Commands Randomly Disappear
- **Cause:** Race condition in `app/alerts/discord_bot.py:80-86`
```python
synced = await asyncio.wait_for(self.tree.sync(guild=guild), timeout=30.0)
```
- **Problem:** If sync times out or crashes mid-deployment, commands aren't registered
- **Evidence:** Log shows `âŒ Command sync timed out after 30s` or `âŒ Command sync failed`

#### B. Web Service Configuration Issues
- **Misconfiguration:** Web service has `SCHEDULER_ENABLED=true` + `DISCORD_BOT_ENABLED=true`
- **Problem:** These flags should be `false` on web service (only needs REST API)
- **Impact:** Minor (flags not used in web context), but confusing for debugging

#### C. Redis Free Tier Limit Risk
- **Limit:** 10K commands/day = **417 commands/hour**
- **Current usage estimate:**
  - Token cache reads: ~120/hour (every 30s for scheduler jobs)
  - Rate limiting: ~60/hour (user commands)
  - Session storage: ~50/hour
  - **Total:** ~230/hour = **5,520/day** (55% of limit) âœ… Safe for now

---

## 4. Stabilization Recommendations

### ðŸŽ¯ Phase 1: Immediate Fixes (Stop the Bleeding)

#### 1.1 Fix HTTP Session Leaks in Discord Bot
**File:** `app/alerts/helpers/api_client.py`

**Problem:** Creating new `ClientSession` on every request.

**Solution:** Reuse single session per API client instance.

```python
# BEFORE (current - leaks memory):
async def recommend_strategy(self, ...):
    async with aiohttp.ClientSession(timeout=self.timeout) as session:
        async with session.post(url, json=body) as response:
            ...

# AFTER (fixed - reuse session):
class StrategyRecommendationAPI:
    def __init__(self, base_url: str, timeout: int = 30):
        self.base_url = base_url.rstrip("/")
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self._session: aiohttp.ClientSession | None = None

    async def _get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession(timeout=self.timeout)
        return self._session

    async def close(self) -> None:
        if self._session and not self._session.closed:
            await self._session.close()

    async def recommend_strategy(self, ...):
        session = await self._get_session()
        async with session.post(url, json=body) as response:
            ...
```

**Impact:** Reduces memory by **50-100 MB** (eliminates session leak).

---

#### 1.2 Add Explicit Client Cleanup in Scheduler Jobs
**File:** `app/workers/jobs.py`

**Problem:** `BaseAPIClient` instances never call `close()`.

**Solution:** Use context managers in job wrappers.

```python
# BEFORE (current):
async def realtime_prices_job(timeframe: Timeframe = Timeframe.ONE_MINUTE):
    async with async_session_maker() as session:
        inserted = await tasks.fetch_realtime_prices(session, timeframe=timeframe)

# AFTER (fixed):
async def realtime_prices_job(timeframe: Timeframe = Timeframe.ONE_MINUTE):
    async with async_session_maker() as session:
        inserted = await tasks.fetch_realtime_prices(session, timeframe=timeframe)

    # Explicitly cleanup provider clients after job
    from app.services.provider_manager import provider_manager
    await provider_manager.cleanup()  # Close all httpx clients
```

**Impact:** Reduces persistent memory by **30-60 MB**.

---

#### 1.3 Increase Scheduler Misfire Grace Time
**File:** `app/workers/scheduler.py:53`

**Problem:** 30s grace time too short for 60-90s jobs.

**Solution:** Increase to 120s to prevent overlapping jobs.

```python
# BEFORE:
scheduler.add_job(
    realtime_prices_job,
    trigger="interval",
    seconds=120,
    misfire_grace_time=30,  # Too short!
)

# AFTER:
scheduler.add_job(
    realtime_prices_job,
    trigger="interval",
    seconds=120,
    misfire_grace_time=120,  # Skip job if previous still running
)
```

**Impact:** Prevents job overlap = **eliminates 100-200 MB spikes**.

---

### ðŸ”§ Phase 2: Configuration Tuning

#### 2.1 Fix Web Service Environment Variables
**Platform:** Render Dashboard â†’ Web Service â†’ Environment

**Changes:**
```bash
# CURRENT (incorrect):
SCHEDULER_ENABLED=true     # âŒ Web service shouldn't run scheduler
DISCORD_BOT_ENABLED=true   # âŒ Web service shouldn't run bot

# FIXED:
SCHEDULER_ENABLED=false    # âœ… Only REST API
DISCORD_BOT_ENABLED=false  # âœ… Only REST API
```

---

#### 2.2 Reduce Batch Size in Realtime Job
**File:** `app/config.py:121`

**Problem:** 25 tickers per batch Ã— 500 tickers = 20 iterations Ã— 5s = 100s.

**Solution:** Reduce batch size to 10-15 for faster cycles.

```python
# BEFORE:
REALTIME_SYNC_BATCH_SIZE: int = Field(default=25, ...)

# AFTER:
REALTIME_SYNC_BATCH_SIZE: int = Field(default=15, ...)
```

**Impact:** Reduces job duration to **50-75s** = lower memory accumulation.

---

#### 2.3 Prune Rate Limit Dictionary
**File:** `app/alerts/discord_bot.py:116`

**Problem:** `user_command_count` never cleaned.

**Solution:** Add periodic cleanup in rate limiter.

```python
def check_rate_limit(self, user_id: int, max_per_minute: int = 3) -> bool:
    now = asyncio.get_event_loop().time()

    # Prune stale users (no activity in 1 hour)
    stale_users = [uid for uid, timestamps in self.user_command_count.items()
                   if not timestamps or now - timestamps[-1] > 3600]
    for uid in stale_users:
        del self.user_command_count[uid]

    # Rest of rate limiting logic...
```

**Impact:** Prevents slow dictionary growth (minor, but good hygiene).

---

### ðŸš€ Phase 3: Architectural Improvements

#### 3.1 Upgrade Background Worker to Starter+ ($25/month)
**Why:** 512 MB insufficient for scheduler + bot + 6 API clients.

**Recommendation:** Upgrade to **Standard plan (2 GB RAM)**.

**Cost:** $25/month (vs. current $7/month).

**Benefit:**
- **4Ã— memory headroom** = no more crashes
- Allows future scaling (more tickers, more jobs)

---

#### 3.2 Split Background Worker into Two Services
**Alternative to 3.1** (if staying on free/starter tiers):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CURRENT: 1 Background Worker (512 MB)                      â”‚
â”‚  â”œâ”€ Discord bot + 3 polling tasks                           â”‚
â”‚  â””â”€ APScheduler + 5 jobs                                    â”‚
â”‚     â””â”€ Memory: 450-480 MB (crashes)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROPOSED: 2 Separate Services                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Service A: Discord Bot (Free tier - 512 MB)       â”‚   â”‚
â”‚  â”‚  â”œâ”€ Command: python -m app.alerts                  â”‚   â”‚
â”‚  â”‚  â”œâ”€ Env: SCHEDULER_ENABLED=false                   â”‚   â”‚
â”‚  â”‚  â”œâ”€ Components: Discord bot + polling tasks        â”‚   â”‚
â”‚  â”‚  â””â”€ Memory: ~200-250 MB âœ…                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Service B: Scheduler (Free tier - 512 MB)         â”‚   â”‚
â”‚  â”‚  â”œâ”€ Command: python -m app.workers                 â”‚   â”‚
â”‚  â”‚  â”œâ”€ Env: SCHEDULER_ENABLED=true                    â”‚   â”‚
â”‚  â”‚  â”œâ”€ Components: APScheduler jobs only              â”‚   â”‚
â”‚  â”‚  â””â”€ Memory: ~300-350 MB âœ…                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  ðŸ’° Cost: Same ($0 + $7 = $7/month or $0 + $0 = free)      â”‚
â”‚  âœ… Benefit: Isolation = no memory contention              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation:**
1. Create new Render service: "Volaris Scheduler"
2. Start command: `python -m app.workers.__main__` (create this file)
3. Set `SCHEDULER_ENABLED=true`, `DISCORD_BOT_ENABLED=false`
4. Update existing background worker: Set `SCHEDULER_ENABLED=false`

---

#### 3.3 Add Memory Profiling and Alerts
**File:** `app/workers/scheduler.py:20`

**Already implemented:** Memory logging in `_log_job_memory()` âœ…

**Enhancement:** Add Sentry alert when memory > 400 MB.

```python
def _log_job_memory(event):
    memory = get_memory_usage()
    app_logger.info("job_completed", extra={...})

    # Alert if memory dangerously high
    if memory["rss_mb"] > 400:
        app_logger.warning(
            "high_memory_usage",
            extra={"memory_mb": memory["rss_mb"], "job_id": event.job_id}
        )
        # Trigger manual GC to free memory
        import gc
        gc.collect()
```

---

## 5. Priority Action Plan

### Week 1: Critical Fixes (Stop Crashes)
1. âœ… **Fix aiohttp session leaks** (api_client.py) â†’ PR #1
2. âœ… **Add client cleanup in jobs** (jobs.py + provider_manager.py) â†’ PR #2
3. âœ… **Increase misfire grace time** (scheduler.py) â†’ PR #3
4. âœ… **Fix web service env vars** (Render dashboard) â†’ No code change

**Expected outcome:** Background worker stable for 1-2 hours (vs. 10-20 min).

---

### Week 2: Optimization
5. âœ… **Reduce batch size to 15** (config.py) â†’ PR #4
6. âœ… **Add rate limit dict pruning** (discord_bot.py) â†’ PR #5
7. âœ… **Add GC trigger on high memory** (scheduler.py) â†’ PR #6

**Expected outcome:** Background worker stable for 4-6 hours.

---

### Week 3: Scaling Decision
8. **Option A:** Upgrade background worker to Standard ($25/month)
9. **Option B:** Split into 2 services (Discord + Scheduler)

**Recommendation:** Start with **Option B** (free), upgrade to **Option A** if still unstable.

---

## 6. Quick Reference: Key Files & Line Numbers

| **Issue** | **File** | **Lines** | **Fix** |
|---|---|---|---|
| Session leaks | `app/alerts/helpers/api_client.py` | 72-80 | Reuse ClientSession |
| Unclosed httpx clients | `app/services/base_client.py` | 43-53 | Add cleanup in jobs |
| Job overlap | `app/workers/scheduler.py` | 53 | Increase grace time |
| Long job duration | `app/workers/tasks.py` | 116-127 | Reduce batch size |
| Rate limit dict growth | `app/alerts/discord_bot.py` | 116-129 | Prune old entries |
| Command sync timeout | `app/alerts/discord_bot.py` | 80-86 | Add retry logic |
| Web service config | Render Dashboard | Env vars | Set SCHEDULER_ENABLED=false |

---

## 7. Expected Memory Profile After Fixes

```
BEFORE (current):
â”œâ”€ Baseline: 250 MB (Discord bot + scheduler + DB pool)
â”œâ”€ Session leaks: +50-100 MB/10min (cumulative)
â”œâ”€ Job execution: +100-200 MB (spikes)
â””â”€ Total: 450-480 MB â†’ ðŸ’¥ CRASH

AFTER (Phase 1 fixes):
â”œâ”€ Baseline: 200 MB (cleaned up clients)
â”œâ”€ Session leaks: 0 MB (fixed)
â”œâ”€ Job execution: +80-120 MB (reduced batch + no overlap)
â””â”€ Total: 280-320 MB â†’ âœ… STABLE (40% headroom)

AFTER (Phase 2 + split services):
Service A (Discord Bot):
â””â”€ Total: 150-200 MB â†’ âœ… STABLE (60% headroom)

Service B (Scheduler):
â””â”€ Total: 250-300 MB â†’ âœ… STABLE (40% headroom)
```

---

## 8. Monitoring & Validation

### Key Metrics to Track

**Memory Usage:**
- Baseline memory after startup
- Memory growth rate (MB/hour)
- Peak memory during job execution
- Memory after GC cycles

**Job Performance:**
- Job execution time (realtime_prices_job should be < 90s)
- Job success rate (should be > 95%)
- Job overlap incidents (should be 0)

**API Health:**
- HTTP session count (should be constant, not growing)
- Provider API error rate (should be < 5%)
- Redis command usage (should stay < 8K/day)

**Discord Bot:**
- Command sync success rate (should be 100%)
- Command response time (should be < 5s)
- Alert/stream polling failures (should be 0)

### Validation Steps After Each Phase

**Phase 1 Validation:**
```bash
# 1. Deploy fixes
# 2. Monitor for 2 hours
# 3. Check logs for memory warnings
grep "high_memory_usage" /var/log/render/*.log

# 4. Verify no OOM crashes
grep "killed" /var/log/render/*.log

# 5. Check job completion
grep "job_completed" /var/log/render/*.log | tail -20
```

**Phase 2 Validation:**
```bash
# 1. Monitor for 6 hours
# 2. Verify batch size reduction
grep "Realtime prices job complete" /var/log/render/*.log

# 3. Check rate limit dict size (add debug log)
grep "rate_limit_dict_size" /var/log/render/*.log
```

**Phase 3 Validation:**
```bash
# 1. Monitor for 24 hours
# 2. Compare memory profiles between services
# 3. Verify no crashes in either service
```

---

## 9. Rollback Plan

If fixes introduce regressions:

**Phase 1 Rollback:**
```bash
git revert <commit-hash>
git push origin main
# Render auto-deploys from main
```

**Phase 2 Rollback:**
- Revert config changes in Render dashboard
- Restart services

**Phase 3 Rollback:**
- Delete new scheduler service
- Re-enable scheduler in background worker
- Set `SCHEDULER_ENABLED=true` in background worker

---

## 10. Future Improvements (Post-Stabilization)

### Performance Optimizations
1. **Connection pooling:** Share httpx clients across jobs via dependency injection
2. **Caching:** Cache option chain data for 5 minutes to reduce API calls
3. **Batching:** Use bulk upserts for price data (currently 1 row at a time)
4. **Async improvements:** Use `asyncio.gather()` for parallel ticker fetches

### Scalability Enhancements
1. **Dynamic ticker selection:** Only fetch prices for tickers with active alerts/streams
2. **Job prioritization:** Use APScheduler job priorities for critical tasks
3. **Horizontal scaling:** Add load balancer for multiple web service instances
4. **Rate limit sharing:** Use Redis for cross-instance rate limiting

### Observability
1. **Metrics dashboard:** Integrate Grafana for real-time monitoring
2. **Alerting:** Set up PagerDuty for critical failures
3. **Tracing:** Add OpenTelemetry for distributed tracing
4. **Profiling:** Run periodic memory profiling in production

---

**Document Version:** 1.0
**Last Updated:** 2025-10-15
**Author:** Claude (Volaris Deployment Analysis)
